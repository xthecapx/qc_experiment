to reference: \cite{knillRandomizedBenchmarkingQuantum2008_2008}

Randomized Benchmarking of Quantum Gates

A key requirement for scalable quantum computing is that elementary quantum gates can be implemented with sufficiently low error. One method for determining the error behavior of a gate implementation is to perform process tomography. However, standard process tomography is limited by errors in state preparation, measurement and one-qubit gates. It suffers from inefficient scaling with number of qubits and does not detect adverse errorcompounding when gates are composed in long sequences. An additional problem is due to the fact that desirable error probabilities for scalable quantum computing are of the order of 0.0001 or lower. Experimentally proving such low errors is challenging. We describe a randomized benchmarking method that yields estimates of the computationally relevant errors without relying on accurate state preparation and measurement. Since it involves long sequences of randomly chosen gates, it also verifies that error behavior is stable when used in long computations. We implemented randomized benchmarking on trapped atomic ion qubits, establishing a one-qubit error probability per randomized π/2 pulse of 0.00482(17) in a particular experiment. We expect this error probability to be readily improved with straightforward technical modifications.

In principle, quantum computing can be used to solve computational problems having no known efficient classical solutions, such as factoring and quantum physics simulations, and to significantly speed up unstructured searches and Monte-Carlo simulations [1, 2, 3, 4]. In order to realize these advantages of quantum computing, we need to coherently control large numbers of qubits for many computational steps. The smallest useful instances of the above-mentioned algorithmic applications require hundreds of qubits and many millions of steps. A quantum computing technology that realistically can be used to implement sufficiently large quantum computations is said to be “scalable”. Current quantum computing technologies that promise to be scalable have demonstrated preparation of nontrivial quantum states of up to 8 qubits [5], but it is not yet possible to apply more than a few sequential two-qubit gates without excessive loss of coherence. Although there have been experiments to determine the behavior of isolated gates applied to prepared initial states [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], there have been no experiments to determine the noise affecting gates in a general computational context. An important challenge of quantum computing experiments is to physically realize gates that ∗knill@boulder.nist.gov †Present address: University of Ulm, Ulm, Germany ‡Present address: Lockheed Martin, Huntsville, Alabama §Present address: Weizmann Institute of Science, Rehovot, Israe

2 have low error whenever and wherever they are applied. Studies of fault-tolerant quantum computing suggest that in order to avoid excessive resource overheads, the probability of error per unitary gate should be well below 10−2 [16, 17, 18]. The current consensus is that it is a good idea to aim for error probabilities below 10−4. What experiments can be used to verify such low error probabilities? One approach is to use process tomography to establish the complete behavior of a quantum gate. This requires that the one-qubit gates employed in the tomography have lower error than the bound to be established on the gate under investigation. If this requirement is met, process tomography gives much useful information about the behavior of the gate, but fails to establish that the gate will work equally well in every context where it may be required. Process tomography can also be very time consuming as its complexity scales exponentially with the number of qubits. We propose a randomized benchmarking method to determine the error probability per gate in computational contexts. Randomization has been suggested as a tool for characterizing features of quantum noise in [19]. The authors propose implementing random unitary operators U followed by their inverses U−1. Under the assumption that the noise model can be represented by a quantum operation acting independently between the implementations of U and U−1, the effect of the randomization is to depolarize the noise. The average fidelity of the process applied to a pure initial state is the same as the average over pure states of the fidelity of the noise operation. (The latter average is known as the average fidelity and is closely related to the entanglement fidelity of an operation [20].) They also show that the average fidelity can be obtained with few random experiments. They then consider self-inverting sequences of random unitary operations of arbitrary length. Assuming that the noise can be represented by quantum operations that do not depend on the choice of unitaries, the fidelity-decay of the sequence is shown to represent the strength of the noise. Our randomized benchmarking procedure simplifies this procedure by restricting the unitaries to Clifford gates and by not requiring that the sequence is strictly self-inverting. An alternative approach to verifying that sequences of gates realize the desired quantum computation is given in [21]. In this approach, successively larger parts of quantum networks are verified by making measurements involving their action on entangled states. This “self testing” strategy is very powerful and provably works under minimal assumptions on gate noise. It is theoretically efficient but requires significantly more resources and multisystem control than randomized benchmarking. Our randomized benchmarking method involves applying random sequences of gates of varying lengths to a standard initial state. Each sequence ends with a randomized measurement that determines whether the correct final state was obtained. The average computationally relevant error per gate is obtained from the increase in error probability of the final measurements as a function of sequence length. The random gates are taken from the Clifford group [22], which is generated by π/2 rotations of the form e−iσπ/4 with σ a product of Pauli operators acting on different qubits. The restriction to the Clifford group ensures that the measurements can be of one-qubit Pauli operators that yield at least one deterministic one-bit answer in the absence of errors. The restriction is justified by the fact that typical fault-tolerant architectures (those based on stabilizer codes) are most sensitive to errors in elementary Clifford gates such as the controlled NOT. Provided the errors in these gates are tolerated, other gates needed for universality are readily implemented [16, 23]. Note that the results of [19] hold if the unitaries are restricted to the Clifford group, because the Clifford group already has the property that noise is depolarized. We believe that randomized benchmarking yields computationally relevant errors even when the noise is induced by, and depends on, the gates, as is the case in practice. Randomized benchmarking as discussed and implemented here gives an overall average fidelity for the noise in gates. To obtain more specific information, the technique needs to be refined. In [24], randomization by error-free one-qubit unitaries is used to obtain more detailed information about noise acting on a multiqubit system. Randomized benchmarking can be adapted to use similar strategies

II. RANDOMIZED BENCHMARK OF ONE QUBIT For one qubit, our randomized benchmarking procedure consists of a large number of experiments, where each experiment consists of a pulse sequence that requires preparing an initial quantum state ρ, applying an alternating sequence of either major-axis π pulses or identity operators (“Pauli randomization”) and π/2 pulses (“computational gates”), and performing a final measurement M. The pulse sequence between state preparation and measurement begins and ends with π pulses. For one qubit, the initial state is |0〉. Because the major-axis π- and π/2 rotations are in the Clifford group, the state is always an eigenstate of a Pauli operator during the pulse sequence. The Pauli randomization applies unitary operators (“Pauli pulses”) that are (ideally) of the form e±iσbπ/2, where the sign ± and b = 0, x, y, z are chosen uniformly at random and we define σ0 to be the identity operator. For ideal pulses, the choice of sign determines only a global phase. However, in an implementation, the choice of sign can determine a physical setting that may affect the error behavior. The computational gates are π/2 pulses of the form e±iσuπ/4, with u = x, y. The sign and u are chosen uniformly at random, except for the last π/2 pulse, where u is chosen so that the final state is an eigenstate of σz. The computational gates generate the Clifford group for one qubit. Their choice is motivated by the fact that they are experimentally implementable as simple pulses. The final measurement is a von Neumann measurement of σz. The last π/2 pulse ensures that, in the absence of errors, the measurement has a known, deterministic outcome for a given pulse sequence. However, the randomization of the pulse sequence ensures that the outcome is not correlated with any individual pulse or proper subsequence of pulses. The length l of a randomized pulse sequence is its number of π/2 pulses. The π/2 pulses are considered to be the ones that advance a computation. The π pulses serve only to randomize the errors. One can view their effect as being no more than a change of the Pauli frame. The Pauli frame consists of the Pauli operator that needs to be applied to obtain the intended computational state in the standard basis [16]. We call the π/2 and Pauli pulse combinations randomized computational gates. In principle, we can determine a pulse error rate by performing N experiments for each length l = 1, . . . , L to estimate the average probability pl of the incorrect measurement outcome (or “error probability”) for sequences of length l. The relationship between l and pl can be used to obtain an average probability of error per pulse. Suppose that all errors are independent and depolarizing. Let the depolarization probability of an operation A be dA and consider a specific pulse sequence consisting of operations A0, A1A2, . . . , A2l+1A2l+2, A2l+3, where A0 is the state preparation, A1A2 and the following pairs are the randomized computational gates, and A2l+3 the measurement. For the measurement, we can assume that the error immediately precedes a perfect measurement. The state after Ak is a known eigenstate of a Pauli operator or completely depolarized. Depolarization of the state is equivalent to applying a random Pauli or identity operator, each with probability 1/4. The probability of the state’s not having been depolarized is ∏k j=0(1 − dAj ). In particular, we can express pl = E((1 − ∏2l+3 j=0 (1 − dAj ))/2), where the function E(.) gives the expectation over the random choices of the Aj. The factor of 1/2 in the expression for pl arises because depolarization results in the correct state 1/2 of the time. The choices of the Aj are independent except for the last π/2 pulse. Assume that the depolarization probability of the last π/2 pulse does not depend on the previous pulses. We can then write pl = (1 − (1 − dif)(1 − d)l)/2, where d is the average depolarization probability of a random combination of one π/2- and on

4 Pauli pulse (a randomized computational gate), and dif combines the depolarization probabilities of the preparation, initial Pauli pulse and measurement. Thus pl decays exponentially to 1/2, and the decay constant yields d. A commonly used metric to describe the deviation of an implemented gate from the intended gate is the average fidelity Fa, which is defined as the uniform average over pure input states of the fidelity of the output state with respect to the intended output state. We are interested in the average computationally relevant error per step consisting of a randomized computational gate (“average error” for short). This is given by the expectation over gates of 1 − Fa and relates to the depolarization parameter d of the previous paragraph by 1 − Fa = d/2. In our implementation of the randomized computational gates, the π pulses around the z-axis are implemented by changes in rotating frame and do not involve actively applying a pulse. Therefore, on average, the angular distance of the randomized gate’s action is π. As a result, (1 − d/2) represents the average fidelity of pulses with action π. Although estimates of pl are sufficient to obtain the average error for a randomized computational gate, it is useful to consider the error behavior of specific randomized computations and even fixed instances of the randomized sequences. For this purpose, the sequences are generated by first producing NG random sequences consisting of L random computational gates, where the gates are chosen independently without considering the final state. These sequences are considered to be a sample of typical computations. Each sequence is then truncated at different lengths. For each length, a π/2 pulse is appended to ensure that the final state is an eigenstate of σz. The sign of this final pulse is random. The resulting sequences are randomized by inserting the random Pauli pulses. We can then perform experiments to determine the probability of incorrect measurement outcomes for each such sequence and for each truncated computation after randomization by Pauli pulses. To be specific, the procedure is implemented as follows: Randomized benchmarking for one qubit: This obtains measurement statistics for NGNlNP Ne experiments, where NG is the number of different computational gate sequences, Nl is the number of lengths to which the sequences are truncated, NP is the number of Pauli randomizations for each gate sequence, and Ne is the number of experiments for each specific sequence. 1. Pick a set of lengths l1 < l2 < . . . < lNl. The goal is to determine the probability of error of randomized computations of each length. 2. Do the following for each j = 1, . . . , NG: 2.a. Choose a random sequence G = {G1, . . .} of lNl − 1 computational gates. 2.b. For each k = 1, . . . , Nl do the following: 2.b.1. Determine the final state ρf obtained by applying Glk . . . G1 to |0〉, assuming no error. 2.b.2. Randomly pick a final computational gate R among the two ±x, ±y, ±z axis π/2 pulses that result in an eigenstate of σz when applied to ρf . Record which eigenstate is obtained. 2.b.3. Do the following for each m = 1, . . . NP : 2.b.3.a Choose a random sequence P = {P1, . . .} of lk + 2 Pauli pulses. 2.b.3.b. Experimentally implement the pulse sequence that applies Plk+2RPlk+1Glk . . . G1P1 to |0〉 and measures σz, repeating the experiment Ne times

5 2.b.3.c. From the experimental data and the expected outcome of the experiments in the absence of errors (from step 2.b.2), obtain an estimate pj,lk,m of the probability of error. Record the uncertainty of this estimate. The probabilities of error pl are obtained from the pj,lk,m by averaging plk = ∑NG j=1 ∑NP m=1 pj,lk,m/(NGNP ). We also obtain the probabilities of error for each computational gate sequence, pj,lk = ∑NP m=1 pj,lk,m/NP . If the errors are independent and depolarizing, the pj,lk,m and the pj,lk should not differ significantly from the plk . However, if the errors are systematic in the sense that each implemented pulse differs from the ideal pulse by a pulse-dependent unitary operator, this can be observed in the distribution of the pj,lk,m over m. In this case, the final state of each implemented pulse sequence is pure. The deviation of these pure states from the expected states is distributed over the Bloch sphere as m and j are varied. For example, consider the case where plk is close to 1/2. If the errors are systematic, the pj,lk,m are distributed as the probability amplitude of |1〉 for a random pure state. In particular, we are likely to find many instances of j and m where pj,lk,m is close to 0 or 1, that is, differs significantly from 1/2. In contrast, if the error is depolarizing, the pj,lk,m are all close to 1/2 independent of j and m.