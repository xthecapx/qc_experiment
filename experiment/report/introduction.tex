\section*{Introduction}

In recent years, companies like Google, AWS, IonQ, IBM, and Microsoft have led the race to build practical quantum computer (QPU). Up to this day, a number of chips have been released, which include Willow \cite{acharyaQuantumErrorCorrection2025_2025}, Majorana 1 \cite{aasenRoadmapFaultTolerant2025_2025}, Ocelot \cite{puttermanHardwareefficientQuantumErrora_2025} and Heron \cite{abughanemIBMQuantumComputers_2025} taking quantum utility one step closer. A common feature of these state-of-the-art chips is the improvement in error corrections, which in the case of Google and Amazon chips includes randomized benchmarking (RB) at the level of logical qubits.

As new hardware is released, it becomes increasingly important to adopt a set of metrics that allow companies to compare against the state-of-the-art QPUs. One recent metric includes IBM's "layer of fidelity", which evaluates the fidelity of two-qubit gates connected over N qubits, allowing us to estimate how many circuits are required for error mitigation \cite{mckayBenchmarkingQuantumProcessor2023_2023}. Therefore, one of the challenges associated with the quantum utility era is defining a set of valuable metrics to evaluate QPUs. Furthermore, finding metrics to validate quantum software in distributed systems seems a natural next step in benchmarking.

Benchmarking a QPU is a complex task, since it requires evaluating the performance of a technology built on top of layers of abstraction. As of today, logical qubits are distinguished from physical qubits, and benchmarking techniques are used to perform tests on the logical qubit layer. There are two reasons for this: 1) physical qubits are not accessible directly, and 2) the physical qubit architecture includes algorithms and calibration protocols to deal with errors caused by noise and other external factors \cite{campbellRoadsFaulttolerantUniversal2017_2017, tomitaLowdistanceSurfaceCodes_2014}. Consequently, QPU benchmarking used to involve calculating correlations between execution results and pre-runtime metrics such as quantum volume, quantum number, circuit depth, and average error gate (calculated with RB) \cite{proctorBenchmarkingQuantumComputers2025_2025}.

In the literature, multiple benchmarking techniques are described for a single QPU. One common technique is Randomized Benchmarking (RB). RB works by implementing sequences of randomly sampled quantum gates (typically from the Clifford group) and measuring how the fidelity of the final quantum state decreases as the sequence length increases \cite{emersonScalableNoiseEstimation_2005}. As a result, the failure rate directly correlates with the average gate fidelity, which helps to calculate a measurement error \cite{magesanRobustRandomizedBenchmarking_2011}.

Other QC benchmarks include high-level holistic approaches such as quantum volume, noisy intermediate scale quantum algorithms, quantum error correction algorithms, computational problems, and many-qubit standards; low-level holistic methods including mirror circuits, algorithmic benchmarks, direct RB, and cross-entropy; and low-level component benchmarking through tomographic methods and cycle benchmarking \cite{proctorBenchmarkingQuantumComputers2025_2025}.

Although the benchmarking techniques described above provide valuable insights, they are currently limited to evaluating isolated systems, such as single QPUs. As quantum computing, like classical computing, naturally progresses toward distributed architectures, it becomes essential to develop benchmarks that can be executed across physically separated quantum processors. \cite{caleffiDistributedQuantumComputing_2024}

In classical computing, a distributed system's performance is measured through throughput and latency, its scalability is tested by examining the workload on the client and server, the availability of the system is often measured by the degradation of throughput caused by failure, and the consistency of the system is often measured by the staleness of data across different locations \cite{andreoliniBenchmarkingModelsTools_2002}. As opposed than classical computing, QC's distributed system is just getting started. As a first step towards distributed QC, researchers have already achieved teleportation between two physically separate QPUs \cite{kangTeleportingTwoqubitEntanglementa_2025}. 

Motivated by the need to address of quantum distributed systems, we introduce an algorithm inspired by the teleportation protocol that can benchmark either a single or multiple QPUs. As a high-level overview, the algorithm is designed to scale in qubits by connecting bell pairs, and incorporates a RB benchmark applied to both the payload and transport state to calculate operation fidelity.

The remainder of this paper is organized as follows: Section 1 provides background on randomized benchmarking; Section 2 details the proposed algorithm; Section 3 presents the experimental results; and Section 4 concludes the paper.
