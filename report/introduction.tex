\section*{Introduction}

% Industry progress in quantum computing
% Recent chip developments
% Error correction advances

In recent years, companies like Google, AWS, IonQ, IBM, and Microsoft have led the race to build a useful quantum computer (QPU). A number of chips, including Willow \cite{acharyaQuantumErrorCorrection2025_2025} and Majorana 1 \cite{aasenRoadmapFaultTolerant2025_2025}, have been released, taking quantum utility one step closer. Something that is common to these state of the art chips, is the improvement in error corrections, which in the case of the Google and Microsoft chips, include the use of randomized benchmarking (RB) at the logical qubits level.


% Current metrics for QPU evaluation
% Add a transition sentence about how these metrics, while valuable for individual QPUs, may not fully capture distributed quantum system capabilities

Benchmarking a QPU is a complex task, since it requires evaluating the performance of a technology built on top of layers of abstraction. Current state-of-the-art differentiates logical qubits from physical qubits, and benchmarking techniques are used to run analyses on top of logical qubits. The reason for that is, physical qubits are not directly accessible and because of the fact that they include algorithms to deal with errors caused by noise and other external factors \cite{campbellRoadsFaulttolerantUniversal2017_2017, tomitaLowdistanceSurfaceCodes_2014}. As a result, the benchmarking of QPU used to involve finding correlations of the errors in terms of quantum volume, total number of qubits, circuit depth and average error gate (calculated with RB) \cite{proctorBenchmarkingQuantumComputers2025_2025}.

% Challenge of evaluating distributed quantum systems
% Why traditional metrics aren't sufficient for networked quantum computers
% Need for new metrics that consider communication and coordination between quantum nodes

As new hardware is released, it becomes increasingly important to adopt a set of metrics that allow companies to compare against the state-of-the-art QPUs. One recent metric includes IBM's "layer of fidelity", which evaluates the fidelity of two-qubit gates connected over N qubits, allowing us to estimate how many circuits are required for error mitigation \cite{mckayBenchmarkingQuantumProcessor2023_2023}. Consequently, one of the challenges associated with the quantum utility era is defining a set of valuable metrics for evaluating QPUs. Furthermore, finding metrics to validate quantum software in distributed systems seems a natural next step for benchmarking.

% Introduction to quantum teleportation
% Its role as a fundamental protocol for quantum networks
% Why it's a good candidate for benchmarking distributed quantum capabilities

In classical computing, a distributed system's performance is measured through throughput and latency, its scalability is tested by examining the workload on the client and server, the availability of the system is often measured by the degradation of throughput caused by failure, and the consistency of the system is often measured by the staleness of data across different locations \cite{andreoliniBenchmarkingModelsTools_2002}. As opposed than classical computing, QC's distributed system is just getting started. As a first step towards distributed QC, researchers have already achieved teleportation between two physically separate QPUs \cite{kangTeleportingTwoqubitEntanglementa_2025}. Our study presents an algorithm inspired by the teleportation protocol for benchmarking a single QPU that is also extendable to benchmark multiple devices by using the complete protocol.

% Detailed discussion of Random Benchmarking (RB)
% How RB complements teleportation measurements
% Connection to real-world quantum network performance

In the literature, it is possible to identify multiple methods for creating benchmarks for a single QPU. An example of a commonly used technique is Randomized Benchmarking (RB). The RB technique is based on the fact that the inner product of a gate and its inverse is equal to the identity matrix. Due to this relation, the fidelity of a gate can be determined by ensuring that the algorithm has been correctly executed. There are also several techniques for performing QC benchmarks, including: high-level holistic benchmarking like quantum volume, noisy intermediate scale quantum algorithms, quantum error correction algorithms, computational problems and many-quibit standard; low-level holistic benchmarking, like mirror circuits, algorithmic benchmarks, direct RB and cross-entropy; and low-level component benchmarking, such as tomographic methods and cycle benchmarking.

% Introduction of the capacity score metric
% How it combines:
% - Teleportation success rates
% - RB results
% - System performance metrics
% Advantages over existing metrics




% Summary of the contribution
% Paper structure overview
% Impact on quantum network evaluation